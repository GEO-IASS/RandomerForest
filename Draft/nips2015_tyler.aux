\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Breiman2001}
\citation{Delgado2014}
\citation{Caruana2008}
\citation{Heath1993}
\citation{Heath1993}
\citation{Menze2011}
\citation{Heath1993}
\citation{Ho1998}
\citation{Rodriguez2006}
\citation{Menze2011}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{Candes2009}
\@writefile{toc}{\contentsline {section}{\numberline {2}Linear Threshold Tree Ensembles}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Randomer Forests}{2}{section.3}}
\citation{Trunk1979}
\citation{Bickel2004}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Evaluation}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Simulated Data}{3}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Classification performance comparing Random Forest (RF) to several variants of Randomer Forest (RerF), and Bayes optimal performance, on three distinct simulation settings: (A) Trunk, (B) Parity, and (C) Multimodal (see Methods for details). For all settings, the top panel depicts misclassification rate vs. the number of ambient (coordinate) dimensions, and the bottom panel shows a 2D scatter plot of the first 2 coordinates (dashed circles denote the standard deviation level set). Note that in all settings, for all number of dimensions, RerF outperforms RF, even Trunk and Parity, which were designed specifically for RF because the discriminant boundary naturally lies along the coordinate basis.}}{4}{figure.1}}
\newlabel{fig:1}{{1}{4}{Classification performance comparing Random Forest (RF) to several variants of Randomer Forest (RerF), and Bayes optimal performance, on three distinct simulation settings: (A) Trunk, (B) Parity, and (C) Multimodal (see Methods for details). For all settings, the top panel depicts misclassification rate vs. the number of ambient (coordinate) dimensions, and the bottom panel shows a 2D scatter plot of the first 2 coordinates (dashed circles denote the standard deviation level set). Note that in all settings, for all number of dimensions, RerF outperforms RF, even Trunk and Parity, which were designed specifically for RF because the discriminant boundary naturally lies along the coordinate basis}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Classifier training time comparing RF to several variants of RerF, same setting as the top row of Figure 1. The only difference is that the y-axis here labels training time (in seconds). Although RerF requires slightly more time than RF (largely due to random sampling of projection matrices), they scale similarly.}}{4}{figure.2}}
\newlabel{fig:2}{{2}{4}{Classifier training time comparing RF to several variants of RerF, same setting as the top row of Figure 1. The only difference is that the y-axis here labels training time (in seconds). Although RerF requires slightly more time than RF (largely due to random sampling of projection matrices), they scale similarly}{figure.2}{}}
\citation{Delgado 2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Effects of Transformations and Outliers on Classifier Performance}{5}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Real Data}{5}{subsection.4.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{5}{section.5}}
\citation{Caruana2008}
\citation{Caruana2008}
\bibdata{nips2015_tyler}
\bibcite{Breiman2001}{1}
\bibcite{Delgado2014}{2}
\bibcite{Caruana2008}{3}
\bibcite{Heath1993}{4}
\bibcite{Menze2011}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The effect of various transformations applied to the Trunk (panels A-D) and Parity (panels E-H) simulations (see Methods for details) on classification performance of (A,E) RF, (B,F) RerF (s+d), (C,G) RerF (s+d+r), and (D,H) Fisherfaces. Specifically, we consider, rotations, scalings, and affine transformations, as well as introducing outliers. Classification performance of RF is compromised by rotations and therefore affine transformations as well. RerF(s+d) is invariant to rotation, but not scaling and therefore not affine transformation. RerF(s+d+r) is invariant to to affine transformations. Like RerF (s+d), Fisherfaces is invariant to rotation but not scaling. Note that all variants are reasonably robust to outliers.}}{6}{figure.3}}
\newlabel{fig:3}{{3}{6}{The effect of various transformations applied to the Trunk (panels A-D) and Parity (panels E-H) simulations (see Methods for details) on classification performance of (A,E) RF, (B,F) RerF (s+d), (C,G) RerF (s+d+r), and (D,H) Fisherfaces. Specifically, we consider, rotations, scalings, and affine transformations, as well as introducing outliers. Classification performance of RF is compromised by rotations and therefore affine transformations as well. RerF(s+d) is invariant to rotation, but not scaling and therefore not affine transformation. RerF(s+d+r) is invariant to to affine transformations. Like RerF (s+d), Fisherfaces is invariant to rotation but not scaling. Note that all variants are reasonably robust to outliers}{figure.3}{}}
\bibcite{Ho1998}{6}
\bibcite{Rodriguez2006}{7}
\bibcite{Candes2009}{8}
\bibcite{Trunk1979}{9}
\bibstyle{IEEEtran}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces (A) Classification error and training time of Random Forest and Randomer Forests variants for all 121 datasets from the benchmark comparison study by Caruana \cite  {Caruana2008}. (A) Average (dots) and 0.1 standard deviation level sets (dashed lines) for each method. (B) Classification error of Randomer Forest (sparse+delta+robust) vs. that of Random Forest for each of the 121 datasets. The black line indicates equal classification error of the two algorithms. Color indicates dimensionality of the datasets and size of points indicates number of samples. Note that RerF almost always does as well, and often significantly better.}}{7}{figure.4}}
\newlabel{fig:4}{{4}{7}{(A) Classification error and training time of Random Forest and Randomer Forests variants for all 121 datasets from the benchmark comparison study by Caruana \cite {Caruana2008}. (A) Average (dots) and 0.1 standard deviation level sets (dashed lines) for each method. (B) Classification error of Randomer Forest (sparse+delta+robust) vs. that of Random Forest for each of the 121 datasets. The black line indicates equal classification error of the two algorithms. Color indicates dimensionality of the datasets and size of points indicates number of samples. Note that RerF almost always does as well, and often significantly better}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A1}{\ignorespaces The number of trees until a stable misclassification rate is achieved for RF and the RerF variants in the Trunk, parity, and multimodal simulations. Simulation settings are the same as in Fig1. The number of ambient dimensions for panels A, B, and C were chosen to be 1000, 10, and 1000 respectively.}}{7}{figure.1}}
\newlabel{fig:A1}{{A1}{7}{The number of trees until a stable misclassification rate is achieved for RF and the RerF variants in the Trunk, parity, and multimodal simulations. Simulation settings are the same as in Fig1. The number of ambient dimensions for panels A, B, and C were chosen to be 1000, 10, and 1000 respectively}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A2}{\ignorespaces Classification performance comparing Random Forest (RF) to several variants of Randomer Forest (RerF) on the modified Trunk simulation setting. Here, the ith diagonal of the covariance matrices of both classes is equal to the inverse of the difference in means of the ith dimension between the two classes. For small values of p, all variants of RerF perform marginally better than RF. For large values of p, all variants of RerF perform worse than RF.}}{8}{figure.2}}
\newlabel{fig:A2}{{A2}{8}{Classification performance comparing Random Forest (RF) to several variants of Randomer Forest (RerF) on the modified Trunk simulation setting. Here, the ith diagonal of the covariance matrices of both classes is equal to the inverse of the difference in means of the ith dimension between the two classes. For small values of p, all variants of RerF perform marginally better than RF. For large values of p, all variants of RerF perform worse than RF}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A3}{\ignorespaces Scatter plot of parallel cigars in two dimensions. (A) Decision boundaries from a single tree of RF. (B) The decision boundary obtained by projecting the input data onto the difference in class-conditional means. (C) The same as (B), but first passing the input to ranks before computing the difference in means.}}{8}{figure.3}}
\newlabel{fig:A3}{{A3}{8}{Scatter plot of parallel cigars in two dimensions. (A) Decision boundaries from a single tree of RF. (B) The decision boundary obtained by projecting the input data onto the difference in class-conditional means. (C) The same as (B), but first passing the input to ranks before computing the difference in means}{figure.3}{}}
