\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Breiman2001}
\citation{Delgado2014,Caruana2008}
\citation{Heath1993}
\citation{Menze2011}
\citation{Heath1993,Tan2005}
\citation{Ho1998,Rodriguez2006}
\citation{Menze2011}
\citation{Blaser2015}
\newlabel{intro}{{1}{1}{}{section.1}{}}
\citation{Blaser2015}
\newlabel{pseudo}{{1}{2}{}{algorithm.1}{}}
\citation{Li2006}
\citation{Li2006}
\citation{Trunk1979}
\citation{Blaser2015}
\newlabel{section: sims}{{4.1}{3}{}{subsection.4.1}{}}
\newlabel{posteriors}{{1}{4}{Class posteriors for the sparse parity problem in the first two dimensions (refer to section \ref {section: sims} for details). (A): True posteriors. (B) - (D): Posterior estimates for RF, RerF, and RotRF, respectively. Comparing panels B-D with A, it is evident that RerF produces better estimates of the posteriors than does RF or RotRF}{figure.1}{}}
\newlabel{simulations}{{2}{4}{Sparse parity (A-C) and Trunk (D-F) simulations (see section \ref {section: sims} for details). (A) and (D): Scatterplots of sampled points in the first two dimensions. (B) and (E): Error rates of RerF and RotRF relative to RF across different values of p. (C) and (F): Same as (B) and (E) except absolute training time is plotted on the y-axis instead. The cyan, green, and magenta lines correspond to RF, RerF, and RotRF, respectively. This color coding is adopted in figures \ref {transformations} and \ref {benchmark} that follow. Both RerF and RotRF do better than RF when the number of irrelevant features is sufficiently small, due to their ability to generate oblique parititions. However, when the number of irrelevant features becomes large enough, performance of RotRF rapidly degrades. Training times show that RerF scales identically with RF, while RotRF scales poorly with large p (note that in panels E and F, RotRF is only plotted up to $p = 500$ due to computational constraints}{figure.2}{}}
\citation{Delgado2014}
\citation{Dolan2002}
\newlabel{section: trans}{{4.3}{5}{}{subsection.4.3}{}}
\newlabel{transformations}{{3}{5}{The effects of different transformations applied to the sparse parity (A-E) and Trunk (F-J) simulations on classification performance (see section \ref {section: trans} for details). Specifically, we consider rotations, scalings, affine transformations, as well as the addition of outliers. RerF and RotRF outperform RF on sparse parity. The trunk simulations demonstrate clearly that RotRF, while invariant to rotation, is sensitive to affine transformations}{figure.3}{}}
\newlabel{section: benchmark}{{4.4}{5}{}{subsection.4.4}{}}
\citation{Heath1993}
\newlabel{benchmark}{{4}{6}{Classification (panels A-D) and speed (panels E-H) performance profiles on benchmarks with various transformations applied (see section \ref {section: benchmark} for details). AUC denotes the area under the curve. In terms of classification accuracy, RerF outperforms RF in all five data settings and only loses to RotRF when the data is rotated. RF and RerF have comparable training time performance, while RotRF tends to be slower}{figure.4}{}}
\newlabel{section: additions}{{4.5}{6}{}{subsection.4.5}{}}
\citation{biau2008}
\citation{zheng15flashgraph}
\newlabel{robustness}{{5}{7}{The utility of supplementing RerF with supervised projections and rank transforming the data prior to inducing trees (see section \ref {section: additions} for details). The effect of various transformations on classification performance of RF, RerF, RerF(d), RerF(d+r), and RotRF for the Trunk simulation are shown in panels A-E, respectively. Panel D shows that RerF(d+r), which supplements RerF with supervised projections, and passes the data to ranks, is more robust to affine transformations than the other methods}{figure.5}{}}
\bibdata{icml2016_RandomerForest}
\bibcite{biau2008}{{1}{2008}{{Biau et~al.}}{{Biau, Devroye, and Lugosi}}}
\bibcite{Blaser2015}{{2}{2015}{{Blaser \& Fryzlewicz}}{{Blaser and Fryzlewicz}}}
\bibcite{Breiman2001}{{3}{2001}{{Breiman}}{{}}}
\bibcite{Caruana2008}{{4}{2008}{{Caruana et~al.}}{{Caruana, Karampatziakis, and Yessenalina}}}
\bibcite{Dolan2002}{{5}{2008}{{Dolan \& Mor\'e}}{{Dolan and Mor\'e}}}
\bibcite{Delgado2014}{{6}{2014}{{Fernandez-Delgado et~al.}}{{Fernandez-Delgado, Cernadas, Barro, and Amorim}}}
\bibcite{Heath1993}{{7}{1993}{{Heath et~al.}}{{Heath, Kasif, and Salzberg}}}
\bibcite{Ho1998}{{8}{1998}{{Ho}}{{}}}
\bibcite{Li2006}{{9}{2006}{{Li et~al.}}{{Li, Hastie, and Church}}}
\bibcite{Menze2011}{{10}{2011}{{Menze et~al.}}{{Menze, Kelm, Splitthoff, Koethe, and Hamprecht}}}
\bibcite{Rodriguez2006}{{11}{2006}{{Rodriguez et~al.}}{{Rodriguez, Kuncheva, and Alonso}}}
\bibcite{Tan2005}{{12}{2005}{{Tan \& Dowe}}{{Tan and Dowe}}}
\bibcite{Trunk1979}{{13}{1979}{{Trunk}}{{}}}
\bibcite{zheng15flashgraph}{{14}{2015}{{Zheng et~al.}}{{Zheng, Mhembere, Burns, Vogelstein, Priebe, and Szalay}}}
\bibstyle{icml2016}
